{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c91a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "page_sep = '<><><><><><>NEWPAGE<><><><><><>'\n",
    "\n",
    "def load_mmd(path: str | Path,\n",
    "             page_sep: str = page_sep):\n",
    "    \"\"\"Load groundtruth mmd of test_pdf.pdf & split by page\n",
    "    \"\"\"\n",
    "    s = Path(path).read_text(encoding=\"utf-8\")\n",
    "\n",
    "    # normalize\n",
    "    s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\").replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "    # page split\n",
    "    pages = [p.strip(\"\\n\") for p in s.split(page_sep)]\n",
    "\n",
    "    return pages\n",
    "\n",
    "# load\n",
    "pages_base = load_mmd(\"./data/nougat_base.mmd\", page_sep)\n",
    "pages_small = load_mmd(\"./data/nougat_small.mmd\", page_sep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec93effc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "238a13a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 simScore=91.9328\n",
      "1 simScore=99.5202\n",
      "2 simScore=99.5558\n",
      "3 simScore=99.8870\n",
      "4 simScore=99.0998\n",
      "5 simScore=99.8329\n",
      "6 simScore=100.0000\n",
      "7 simScore=100.0000\n",
      "8 simScore=99.9602\n",
      "9 simScore=100.0000\n",
      "10 simScore=99.6243\n",
      "11 simScore=99.8723\n",
      "12 simScore=100.0000\n",
      "13 simScore=99.8680\n",
      "14 simScore=98.5988\n",
      "15 simScore=98.4100\n",
      "16 simScore=99.9182\n",
      "17 simScore=100.0000\n",
      "18 simScore=99.9659\n",
      "19 simScore=99.7521\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pages_base)):\n",
    "\n",
    "    similarity_score = fuzz.ratio(pages_base[i], pages_small[i])\n",
    "\n",
    "    print(f\"{i} simScore={similarity_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1ffdaa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text_base[i]==full_text_small[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf98e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter\n",
    "from typing import Dict, List\n",
    "from difflib import SequenceMatcher\n",
    "import math\n",
    "import re\n",
    "\n",
    "# ---------- text normalization ----------\n",
    "_ws_re = re.compile(r\"\\s+\")\n",
    "def normalize(s: str) -> str:\n",
    "    # Keep math symbols, just standardize whitespace + lowercase\n",
    "    s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    s = _ws_re.sub(\" \", s).strip()\n",
    "    return s.lower()\n",
    "\n",
    "def tokens(s: str) -> List[str]:\n",
    "    return normalize(s).split()\n",
    "\n",
    "# ---------- metrics ----------\n",
    "def seqmatch_ratio(a: str, b: str) -> float:\n",
    "    return SequenceMatcher(None, normalize(a), normalize(b)).ratio()\n",
    "\n",
    "def jaccard_tokens(a: str, b: str) -> float:\n",
    "    A, B = set(tokens(a)), set(tokens(b))\n",
    "    if not A and not B:\n",
    "        return 1.0\n",
    "    inter = len(A & B)\n",
    "    union = len(A | B)\n",
    "    return inter / union if union else 0.0\n",
    "\n",
    "def char_ngrams(s: str, n: int = 3) -> Counter:\n",
    "    s = normalize(s)\n",
    "    if len(s) < n:\n",
    "        return Counter([s]) if s else Counter()\n",
    "    return Counter(s[i:i+n] for i in range(len(s) - n + 1))\n",
    "\n",
    "def cosine_char_3gram(a: str, b: str) -> float:\n",
    "    ca, cb = char_ngrams(a, 3), char_ngrams(b, 3)\n",
    "    if not ca and not cb:\n",
    "        return 1.0\n",
    "    # dot\n",
    "    keys = set(ca) | set(cb)\n",
    "    dot = sum(ca[k] * cb[k] for k in keys)\n",
    "    na = math.sqrt(sum(v*v for v in ca.values()))\n",
    "    nb = math.sqrt(sum(v*v for v in cb.values()))\n",
    "    return (dot / (na * nb)) if (na > 0 and nb > 0) else 0.0\n",
    "\n",
    "def levenshtein(a: str, b: str) -> int:\n",
    "    # Memory-efficient Wagnerâ€“Fischer (O(min(n,m)) space)\n",
    "    a, b = normalize(a), normalize(b)\n",
    "    if a == b:\n",
    "        return 0\n",
    "    if len(a) < len(b):\n",
    "        a, b = b, a\n",
    "    prev = list(range(len(b)+1))\n",
    "    for i, ca in enumerate(a, 1):\n",
    "        curr = [i]\n",
    "        for j, cb in enumerate(b, 1):\n",
    "            ins = curr[j-1] + 1\n",
    "            dele = prev[j] + 1\n",
    "            sub = prev[j-1] + (ca != cb)\n",
    "            curr.append(min(ins, dele, sub))\n",
    "        prev = curr\n",
    "    return prev[-1]\n",
    "\n",
    "def cer_similarity(a: str, b: str) -> float:\n",
    "    # 1 - (edit_distance / max_len)\n",
    "    a_n, b_n = normalize(a), normalize(b)\n",
    "    max_len = max(len(a_n), len(b_n))\n",
    "    if max_len == 0:\n",
    "        return 1.0\n",
    "    return 1.0 - (levenshtein(a_n, b_n) / max_len)\n",
    "\n",
    "# ---------- wrapper ----------\n",
    "def page_similarity(a: str, b: str) -> Dict[str, float]:\n",
    "    m1 = seqmatch_ratio(a, b)\n",
    "    m2 = jaccard_tokens(a, b)\n",
    "    m3 = cosine_char_3gram(a, b)\n",
    "    m4 = cer_similarity(a, b)\n",
    "    # Simple composite (tune weights as you like)\n",
    "    composite = 0.25*m1 + 0.25*m2 + 0.30*m3 + 0.20*m4\n",
    "    return {\n",
    "        \"seqmatch_ratio\": m1,\n",
    "        \"jaccard_tokens\": m2,\n",
    "        \"cosine_char_3gram\": m3,\n",
    "        \"cer_similarity\": m4,\n",
    "        \"composite\": composite,\n",
    "    }\n",
    "\n",
    "# ---------- example usage ----------\n",
    "# full_text_base[i] and full_text_small[i] are your per-page strings\n",
    "def compare_pages(full_text_base: List[str], full_text_small: List[str], i: int = 10):\n",
    "    scores = page_similarity(full_text_base[i], full_text_small[i])\n",
    "    print(f\"Page {i} similarity:\")\n",
    "    for k, v in scores.items():\n",
    "        print(f\"  {k:>18}: {v:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_pages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-intel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
