{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4549ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0d869",
   "metadata": {},
   "source": [
    "## 1. Page break indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c223c25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 12, 26, 36, 45]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy.ndarray.cumsum â€” NumPy v2.2 Manual\n",
    "#\n",
    "\n",
    "page_texts = [\"Hello World.\", \"This is so me.\", \"Thank you.\", \"For this.\", \"Honestly.\"]\n",
    "full_text = \"\".join(page_texts)\n",
    "\n",
    "# line that converts page text\n",
    "page_text_lens = [len(page_t) for page_t in page_texts]\n",
    "page_text_lens = np.concatenate([np.array([0]), np.cumsum(page_text_lens[:-1])]).tolist()\n",
    "\n",
    "page_text_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "128204fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World.\n",
      "- - - - - - -\n",
      "This is so me.\n",
      "- - - - - - -\n",
      "Thank you.\n",
      "- - - - - - -\n",
      "For this.\n",
      "- - - - - - -\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(page_text_lens)-1):\n",
    "    start_idx, end_idx = page_text_lens[i], page_text_lens[i+1]\n",
    "    print(full_text[start_idx : end_idx])\n",
    "    print('- - - - - - -')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b8fb07",
   "metadata": {},
   "source": [
    "## 2. Flatten list of logits, predict, re-strucutre to list of list\n",
    "Nested qualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1387a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, islice\n",
    "from typing import List, Sequence, Any\n",
    "\n",
    "def predict_grouped(classifier, document_page_texts: Sequence[Sequence[str]]) -> List[List[Any]]:\n",
    "    # record original lengths (empties ok)\n",
    "    lengths = [len(pages) for pages in document_page_texts]\n",
    "\n",
    "    # flatten once\n",
    "    flat_inputs = list(chain.from_iterable(document_page_texts))  # preserves order\n",
    "\n",
    "    # single inference call (your model can batch/chunk internally)\n",
    "    flat_preds = classifier.predict(flat_inputs)  # must return len(flat_inputs) items\n",
    "\n",
    "    if len(flat_preds) != len(flat_inputs):\n",
    "        raise ValueError(f\"Prediction length mismatch: got {len(flat_preds)} for {len(flat_inputs)} inputs\")\n",
    "\n",
    "    # regroup by original lengths (iter + islice avoids copying large slices repeatedly)\n",
    "    it = iter(flat_preds)\n",
    "    regrouped = [list(islice(it, n)) for n in lengths]\n",
    "\n",
    "    return regrouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98e46e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record original lengths (empties ok)\n",
    "lengths = [len(page_texts) for page_texts in document_page_texts]\n",
    "# flatten input to SciBERT/Specter\n",
    "flat_document_texts= list(chain.from_iterable(document_page_texts))\n",
    "flat_qualities = self.classifier.predict(flat_document_texts)\n",
    "# regroup into qualities:list[list[int]]\n",
    "it = iter(flat_qualities)\n",
    "qualities = [list(islice(it, n)) for n in lengths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fae7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_predict(s:list[str]) -> int:\n",
    "    \"\"\"Faux-prediction mode\"\"\"\n",
    "    int_list = []\n",
    "    for s_0 in s:\n",
    "        try:\n",
    "            int_list.append(int(s_0[0]))\n",
    "        except:\n",
    "            int_list.append(-1)\n",
    "    return int_list\n",
    "\n",
    "#document_page_texts\n",
    "document_page_texts = [[\"15abc\", \"2ruhr\"], [\"3gfgf\", \"4gfs\", \"5dgfd\"], [\"6xdg\", \"7vd\", \"8kkk\", \"9jt\"], [\"0sfg\"]]\n",
    "\n",
    "# record original lengths (empties ok)\n",
    "lengths = [len(page_list) for page_list in document_page_texts]\n",
    "# flatten once\n",
    "flat_inputs = list(chain.from_iterable(document_page_texts))\n",
    "flat_preds = classifier_predict(flat_inputs)\n",
    "# regroup\n",
    "it = iter(flat_preds)\n",
    "regrouped = [list(islice(it, n)) for n in lengths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e64d097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4, 5], [6, 7, 8, 9], [0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regrouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83013163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
